{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code will pour all the data objects into an S3 bucket using Airflow to obtain search engine results and social media results quickly. It will retrieve Instagram, TikTok, Snapchat, Youtube, Twitter and Reddit API data categorized by geographical coordinate location. Then, it will collect SERP data from Google, Bing and Yahoo and categorize that data by geographic coordinate data. It will also collect GIS data and Census data on each geographic coordinate possible. This will help collect data on local housing markets and consumer price index data.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Models (BERT Neural Networks, etc) equipped with ML OPS technology (EvidentlyAI API) will give users the ability to make trends and draw conclusions with real-time, accurate data. This may be used in conjunction with financial trading technologies to provide real-time sentiment analysis on posts concerning the stock market or a certain publicly traded company.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This will then be displayed as a dashboard in Streamlit where users can see certain statistics based on what they need to see. For example, marketing teams will want to see the social media and search engine trends. The ATTOM API will also allow users the ability to see age trends, ,economic/socioeconomic trends, real estate trends and demographics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collecting Top Instagram Posts by Geographic Coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pip\n",
    "from numba import jit\n",
    "from instagrapi import Client\n",
    "import logging as log\n",
    "import geopy\n",
    "from airflow import DAG\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "latitude=[]\n",
    "longitude=[]\n",
    "\n",
    "@jit\n",
    "def instagram_data_extractor(latitude,longitude):\n",
    "    try:\n",
    "        with DAG(\"\",start_date=datetime(2023,17,3,12), schedule_interval=\"@daily\",):\n",
    "            now=datetime.now()\n",
    "            log.basicConfig(level=log.INFO, filename=f'{now} instagram_etl_log.csv', filemode='w', \n",
    "                format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "            log.debug(f'')\n",
    "    \n",
    "            INSTAGRAM_USERNAME=load_dotenv('INSTAGRAM_USERNAME')\n",
    "            INSTAGRAM_PASSWORD=load_dotenv('INSTAGRAM_PASSWORD')\n",
    "    \n",
    "            cl = Client()\n",
    "            cl.login(INSTAGRAM_USERNAME, INSTAGRAM_PASSWORD)\n",
    "        \n",
    "        # Plug the geographic coordinates in as inputs for the function\n",
    "        # Get all the geographic coordinates and then run the geographic coordinates\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        log.error(e, exc_info=True)\n",
    "\n",
    "    try:\n",
    "        for latitude in list(latitude):\n",
    "            for longitude in list(longitude):\n",
    "                instagram_data_extractor(latitude,longitude)\n",
    "    \n",
    "    except Exception as e:\n",
    "        log.error(e, exc_info=True)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a list of all areas and geographic coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.point import Point\n",
    "geolocator = Nominatim(user_agent=\"market_research_V1\")\n",
    "coordinates_list=[]\n",
    "test_point = Point(5.409999, 0.000000)\n",
    "# x should be latitude and try to find the range it can coexist in\n",
    "# y should be longitude and try to find the range it can coexist in\n",
    "location = geolocator.reverse(query=test_point,exactly_one='True')\n",
    "print(location)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By using a DAG, Instagram search Results will be queried at a certain time interval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning the data containing Top 100 Instagram posts by Geographic Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collecting Top TikTok Posts by Geographic Coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ca1680247713407ad8eed4b370d83512626c0f818c0e09f654efc26ece8f332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
