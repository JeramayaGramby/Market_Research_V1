{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This code will pour all the data objects into an S3 bucket using Airflow to obtain search engine results and social media results quickly. It will retrieve Instagram, TikTok, Snapchat, Youtube, Twitter and Reddit API data categorized by geographical coordinate location. Then, it will collect SERP data from Google, Bing and Yahoo and categorize that data by geographic coordinate data. It will also collect GIS data and Census data on each geographic coordinate possible. This will help collect data on local housing markets and consumer price index data.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Models (BERT Neural Networks, etc) equipped with ML OPS technology (EvidentlyAI API) will give users the ability to make trends and draw conclusions with real-time, accurate data. This may be used in conjunction with financial trading technologies to provide real-time sentiment analysis on posts concerning the stock market or a certain publicly traded company.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This will then be displayed as a dashboard in Streamlit where users can see certain statistics based on what they need to see. For example, marketing teams will want to see the social media and search engine trends. The ATTOM API will also allow users the ability to see age trends, ,economic/socioeconomic trends, real estate trends and demographics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collecting Top Instagram Posts by Geographic Coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pip\n",
    "from numba import jit\n",
    "from instagrapi import Client\n",
    "import logging as log\n",
    "import geopy\n",
    "from geopy import Point\n",
    "from airflow import DAG\n",
    "from datetime import datetime\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "# Make a class in main.py that takes these lists and iterates over them\n",
    "latitude=[]\n",
    "longitude=[]\n",
    "\n",
    "\n",
    "class instagram_data_pipeline(latitude,longitude):\n",
    "    def __init__(self):\n",
    "        self.latitude = latitude\n",
    "        self.longitude = longitude\n",
    "\n",
    "    @jit\n",
    "    def instagram_data_extractor(latitude,longitude):\n",
    "        try:\n",
    "            # Move the stuff below to the Instagram DAG file\n",
    "            with DAG(\"\",start_date=datetime(2023,17,3,12), schedule_interval=\"@daily\",):\n",
    "                now=datetime.now()\n",
    "                log.basicConfig(level=log.INFO, filename=f'{now} instagram_etl_log.csv', filemode='w', \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "                log.debug(f'')\n",
    "        \n",
    "                INSTAGRAM_USERNAME=load_dotenv('INSTAGRAM_USERNAME')\n",
    "                INSTAGRAM_PASSWORD=load_dotenv('INSTAGRAM_PASSWORD')\n",
    "        \n",
    "                cl = Client()\n",
    "                cl.login(INSTAGRAM_USERNAME, INSTAGRAM_PASSWORD)\n",
    "            \n",
    "            # Plug the geographic coordinates in as inputs for the function\n",
    "            # Get all the geographic coordinates and then run the geographic coordinates\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            log.error(e, exc_info=True)\n",
    "\n",
    "        # This goes in the if __name__ == '__main__' section\n",
    "        try:\n",
    "            for latitude in list(latitude):\n",
    "                for longitude in list(longitude):\n",
    "                    instagram_data_extractor(latitude,longitude)\n",
    "        \n",
    "        except Exception as e:\n",
    "            log.error(e, exc_info=True)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a list of all areas and geographic coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Baidu.__init__() missing 1 required positional argument: 'api_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeocoders\u001b[39;00m \u001b[39mimport\u001b[39;00m BaiduV3\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgeopy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpoint\u001b[39;00m \u001b[39mimport\u001b[39;00m Point\n\u001b[1;32m----> 3\u001b[0m geolocator \u001b[39m=\u001b[39m BaiduV3(user_agent\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmarket_research_V1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m coordinates_list\u001b[39m=\u001b[39m[]\n\u001b[0;32m      5\u001b[0m test_point \u001b[39m=\u001b[39m Point(\u001b[39m50.409999\u001b[39m, \u001b[39m78.104600\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Baidu.__init__() missing 1 required positional argument: 'api_key'"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import ArcGIS\n",
    "from geopy.point import Point\n",
    "geolocator = ArcGIS(user_agent=\"market_research_V1\")\n",
    "\n",
    "coordinates_list=[]\n",
    "test_point = Point(50.409999, 78.104600)\n",
    "# test_point2 = Point(5.439999, 0.000000)\n",
    "# x should be latitude and try to find the range it can coexist in\n",
    "# for x in range(0, 84)\n",
    "# y should be longitude and try to find the range it can coexist in\n",
    "# for y in range(-179.999999,179.999999)\n",
    "location1 = geolocator.reverse(query=coordinates_list,exactly_one='True')\n",
    "#location2 = geolocator.reverse(query=coordinates_list,exactly_one='True')\n",
    "print(location1)\n",
    "#print(location2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a list of all geographic coordinates to 6 decimal places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for y in range(int(-179.999999),int(179.999999)):\n",
    "#    print(y)\n",
    "import numpy as np\n",
    "\n",
    "for i in np.arange(-79.999999, 79.999999, 0.000001):\n",
    "    print(i, end=',')\n",
    "# Find the smallest gap in latitude and longitude where the coordinates usually change the location\n",
    "# If it's not consistent then below if the second option\n",
    "# You could create a dataframe of locations with their geographic coordinates\n",
    "# Trim out the duplicates in the dataframe\n",
    "# Then you can return coordinates of places and\n",
    "# \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By using a DAG, Instagram search Results will be queried at a certain time interval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning the data containing Top 100 Instagram posts by Geographic Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Collecting Top TikTok Posts by Geographic Coordinate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ca1680247713407ad8eed4b370d83512626c0f818c0e09f654efc26ece8f332"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
